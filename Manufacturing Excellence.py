# -*- coding: utf-8 -*-
"""Copy of Baking.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y1cDYgMZhuTo_BNYuBkwyloI7fRojcYi

# **Manufacturing Excellence**: üç™üç™
"""

# Importing Dataset
import pandas as pd
data=pd.read_csv('/content/bakery_multivariate_700.csv')
print(data.head())

#Explore the data
print(data.shape)      # Rows, columns
print(data.info())     # Data types, null values
print(data.describe()) # Stats for numerical features

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
data['Root_Cause'] = le.fit_transform(data['Root_Cause'])
data['Maintenance_Required'] = le.fit_transform(data['Maintenance_Required'])

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler

# Copy data
df = data.copy()

# --- 1. Handle missing/invalid values ---
numeric_cols = ['Oven_Temp_C', 'Chamber_Humidity_%', 'Dough_Moisture_%',
                'Mixer_RPM', 'Mixer_Vibration_mms', 'Conveyor_Speed_mpm',
                'Energy_kWh', 'Defective_Count', 'Quality_Score', 'Energy_Cost_Impact_USD']

df[numeric_cols] = df[numeric_cols].replace('-', np.nan).astype(float)
df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())

# --- 2. Encode categorical columns separately ---
cat_cols = ['Root_Cause', 'Maintenance_Required', 'Machine_ID']
le = LabelEncoder()
for col in cat_cols:
    df[col] = le.fit_transform(df[col])

# --- 3. Prepare X for scaling ---
# Only numeric + encoded categorical columns
X_cols = numeric_cols + cat_cols
X = df[X_cols]

# --- 4. Scale numeric features only ---
scaler = StandardScaler()
X[numeric_cols] = scaler.fit_transform(X[numeric_cols])

print(X.head())

import pandas as pd
import matplotlib.pyplot as plt

# 1. Load dataset (replace with your file path in Colab/Drive)
file_path = "/content/bakery_multivariate_700.csv"  # change as needed
df = pd.read_csv(file_path)

# 2. USD to INR conversion (approx, update as per current rate)
usd_to_inr = 83.0

# 3. Compute energy savings if anomaly avoided
df["Energy_Savings_IF_Anomaly_Avoided"] = df.apply(
    lambda row: row["Energy_Cost_Impact_USD"] * usd_to_inr if row["Anomaly_Flag"] == 1 else 0,
    axis=1
)

# 4. Convert Energy Cost Impact to INR as well
df["Energy_Cost_Impact_INR"] = df["Energy_Cost_Impact_USD"] * usd_to_inr

# 5. Clean Root_Cause for readability
def clean_root_cause(value):
    mapping = {
        "Oven_Temp_C": "Oven Temperature Spike",
        "Chamber_Humidity_%": "Chamber Humidity Fluctuation",
        "Dough_Moisture_%": "Dough Moisture Deviation",
        "Mixer_RPM": "Mixer Speed Irregularity",
        "Mixer_Vibration_mms": "Excessive Mixer Vibration",
        "Conveyor_Speed_mpm": "Conveyor Speed Anomaly",
        "Energy_kWh": "Unusual Energy Usage"
    }
    return mapping.get(str(value).strip(), value)

df["Root_Cause_Clean"] = df["Root_Cause"].astype(str).apply(clean_root_cause)

# 6. Aggregate metrics
total_energy_cost_usd = df["Energy_Cost_Impact_USD"].sum()
total_energy_cost_inr = df["Energy_Cost_Impact_INR"].sum()

print("=== Energy Impact Summary ===")
print(f"Total Energy Cost Impact: ‚Çπ{total_energy_cost_inr:,.2f}")

# 7. Aggregate cost per root cause (only anomalies considered)
root_cause_costs = (
    df[df["Anomaly_Flag"] == 1]
    .groupby("Root_Cause_Clean")["Energy_Savings_IF_Anomaly_Avoided"]
    .sum()
    .sort_values(ascending=False)
)

print("\n=== Energy Cost Impact by Root Cause (INR) ===")
print(root_cause_costs)

# 8. Plot financial impact of root causes
plt.figure(figsize=(8,5))
root_cause_costs.plot(kind="bar", color="seagreen")
plt.title("Financial Impact of Energy Losses by Root Cause")
plt.xlabel("Root Cause")
plt.ylabel("Energy Cost Impact (INR)")
plt.xticks(rotation=45, ha="right")
plt.tight_layout()
plt.show()

# 9. Save processed file with new metrics
output_file = "/content/bakery_multivariate_700.csv"
df.to_csv(output_file, index=False)
print(f"\nProcessed file saved at: {output_file}")

#Convert categorical to numerical
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
data['Root_Cause'] = le.fit_transform(data['Root_Cause'])
data['Maintenance_Required'] = le.fit_transform(data['Maintenance_Required'])

""" 1. Logistic Regression
 2. Random Forest
 3. XGBoost
 4. Isolation Forest (Unsupervised Anomaly Detection)
"""

print(df.columns)

from sklearn.model_selection import train_test_split

# Suppose your target is Anomaly (or Quality_Score depending on task)
y = df['Anomaly_Flag']

# Features (remove leakage + IDs)
X = df.drop(['Timestamp', 'Batch_ID', 'Anomaly_Flag',
             'Quality_Score', 'Maintenance_Required',
             'Energy_Cost_Impact_USD', 'Root_Cause'], axis=1)                      # target (original, not scaled)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder

# --- Copy original data ---
df_clean = df.copy()

# --- Encode categorical columns (if any) ---
cat_cols = ['Root_Cause', 'Maintenance_Required', 'Machine_ID']
le = LabelEncoder()
for col in cat_cols:
    df_clean[col] = le.fit_transform(df_clean[col].astype(str))

# --- Select features (remove leakage + IDs) ---
X = df_clean.drop([
    'Timestamp', 'Batch_ID', 'Anomaly_Flag',
    'Quality_Score', 'Energy_Cost_Impact_USD', 'Root_Cause'
], axis=1)

# --- Replace bad entries (like '-') with NaN ---
X = X.replace('-', np.nan)

# --- Only keep numeric columns ---
numeric_cols = X.select_dtypes(include=[np.number]).columns
X_numeric = X[numeric_cols]

# --- Fill missing values with column mean ---
X_numeric = X_numeric.fillna(X_numeric.mean())

# --- Scale numeric features ---
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_numeric)

print("‚úÖ Data cleaned and scaled successfully.")
print("Scaled feature shape:", X_scaled.shape)

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, IsolationForest
from xgboost import XGBClassifier
from sklearn.metrics import confusion_matrix, classification_report

# --- Step 1: Copy original data ---
df_clean = df.copy()

# --- Step 2: Encode categorical columns (if any) ---
cat_cols = ['Machine_ID']  # Only operational identifiers, not Root_Cause or Maintenance_Required
le = LabelEncoder()
for col in cat_cols:
    df_clean[col] = le.fit_transform(df_clean[col].astype(str))

# --- Step 3: Select features (remove leakage + IDs + target) ---
# Only operational / process features are kept
X = df_clean[[
    'Machine_ID', 'Oven_Temp_C', 'Chamber_Humidity_%',
    'Dough_Moisture_%', 'Mixer_RPM', 'Mixer_Vibration_mms',
    'Conveyor_Speed_mpm', 'Energy_kWh', 'Defective_Count'
]]

y = df_clean['Anomaly_Flag']

# --- Step 4: Handle missing / bad values ---
X = X.replace('-', np.nan)
numeric_cols = X.select_dtypes(include=[np.number]).columns
X[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())

# --- Step 5: Scale numeric features ---
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# --- Step 6: Train-Test Split ---
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y
)

# --- Step 7: Models ---
# Logistic Regression
lr = LogisticRegression(class_weight="balanced", random_state=42)
lr.fit(X_train, y_train)
y_pred_lr = lr.predict(X_test)

# Random Forest
rf = RandomForestClassifier(n_estimators=100, class_weight="balanced", random_state=42)
rf.fit(X_train, y_train)
y_pred_rf = rf.predict(X_test)

# XGBoost
xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)
xgb.fit(X_train, y_train)
y_pred_xgb = xgb.predict(X_test)

# Isolation Forest (unsupervised)
iso = IsolationForest(contamination=0.1, random_state=42)
y_pred_iso = iso.fit_predict(X_test)
y_pred_iso = np.where(y_pred_iso == -1, 1, 0)

# --- Step 8: Print results ---
def print_results(name, y_true, y_pred):
    print(f"\nüîπ {name} Results")
    print(confusion_matrix(y_true, y_pred))
    print(classification_report(y_true, y_pred))

print_results("Logistic Regression", y_test, y_pred_lr)
print_results("Random Forest", y_test, y_pred_rf)
print_results("XGBoost", y_test, y_pred_xgb)
print_results("Isolation Forest", y_test, y_pred_iso)

"""Compare model *performance*"""

from sklearn.metrics import f1_score, roc_auc_score

models = {
    "LogReg": (y_test, y_pred_lr),
    "RandomForest": (y_test, y_pred_rf),
    "XGBoost": (y_test, y_pred_xgb),
    "IsolationForest": (y_test, y_pred_iso)
}

for name, (yt, yp) in models.items():
    print(f"\nüìä {name}")
    print("F1 (Anomalies):", f1_score(yt, yp, pos_label=1))
    print("ROC-AUC:", roc_auc_score(yt, yp))

"""Try SMOTE + Random Forest/XGB and check if anomaly F1 improves above 0.7."""

# --- SMOTE for imbalance handling ---
from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=42)
X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)

print("Before SMOTE:", y_train.value_counts().to_dict())
print("After SMOTE:", y_train_sm.value_counts().to_dict())

# --- Retrain Random Forest with SMOTE data ---
rf_sm = RandomForestClassifier(n_estimators=200, class_weight="balanced", random_state=42)
rf_sm.fit(X_train_sm, y_train_sm)
y_pred_rf_sm = rf_sm.predict(X_test)

# --- Retrain XGBoost with SMOTE data ---
xgb_sm = XGBClassifier(
    n_estimators=200,
    max_depth=5,
    learning_rate=0.1,
    scale_pos_weight=1,   # because SMOTE balances data
    eval_metric='logloss',
    random_state=42
)
xgb_sm.fit(X_train_sm, y_train_sm)
y_pred_xgb_sm = xgb_sm.predict(X_test)

# --- Compare results again ---
models_sm = {
    "RandomForest_SMOTE": (y_test, y_pred_rf_sm),
    "XGBoost_SMOTE": (y_test, y_pred_xgb_sm)
}

from sklearn.metrics import f1_score, roc_auc_score, classification_report, confusion_matrix

for name, (yt, yp) in models_sm.items():
    print(f"\nüìä {name}")
    print(confusion_matrix(yt, yp))
    print(classification_report(yt, yp))
    print("F1 (Anomalies):", f1_score(yt, yp, pos_label=1))
    print("ROC-AUC:", roc_auc_score(yt, yp))

"""**Feature importance will show which variables drive anomalies.**"""

import pandas as pd
import matplotlib.pyplot as plt

# Get feature importances from the trained Random Forest (after SMOTE)
feat_importances = pd.Series(rf_sm.feature_importances_, index=X.columns)

# Sort descending
feat_importances = feat_importances.sort_values(ascending=False)
print("Random Forest Feature Importances:\n", feat_importances)

# Plot top 10
plt.figure(figsize=(10,6))
feat_importances.head(10).plot(kind='barh')
plt.gca().invert_yaxis()
plt.title("Top 10 Feature Importances (Random Forest)")
plt.xlabel("Importance Score")
plt.show()

# Using built-in XGBoost plot
from xgboost import plot_importance
print("XB Boost Feature Importances:\n", feat_importances)
plt.figure(figsize=(10,6))
plot_importance(xgb_sm, max_num_features=10)
plt.title("Top 10 Feature Importances (XGBoost)")
plt.show()

# Coefficients indicate influence on anomaly (positive ‚Üí increases anomaly likelihood)
coef = pd.Series(lr.coef_[0], index=X.columns).sort_values(ascending=False)
print("Logistic Regression Coefficients:\n", coef)

plt.figure(figsize=(10,6))
coef.head(10).plot(kind='barh')
plt.gca().invert_yaxis()
plt.title("Top 10 Coefficients (Logistic Regression)")
plt.show()

"""# ***SHAP analysis***

"""

!pip install shap

import shap

# For Tree-based models (RandomForest / XGBoost)
explainer_rf = shap.TreeExplainer(rf_sm)  # Random Forest
explainer_xgb = shap.TreeExplainer(xgb_sm)  # XGBoost

# Use test data
shap_values_rf = explainer_rf.shap_values(X_test)
shap_values_xgb = explainer_xgb.shap_values(X_test)

# Random Forest
shap.summary_plot(shap_values_rf, X_test, feature_names=X.columns, plot_type="bar", max_display=10)

# XGBoost
shap.summary_plot(shap_values_xgb, X_test, feature_names=X.columns, plot_type="bar", max_display=10)

import shap
import pandas as pd
import numpy as np

# Convert X_test to DataFrame
X_test_df = pd.DataFrame(X_test, columns=X.columns)

# Find first anomaly
anomaly_indices = np.where(y_test.values == 1)[0]
if len(anomaly_indices) == 0:
    print("No anomalies in test set!")
else:
    anomaly_idx = anomaly_indices[0]
    print("Analyzing test sample index:", anomaly_idx)

    # Prepare SHAP values for class 1 (anomaly)
    if isinstance(shap_values_rf, list):  # TreeExplainer for binary classifier
        # shap_values_rf[1] = class 1
        shap_vals_sample = shap_values_rf[1][anomaly_idx]  # shape = (num_features,)
        expected_val = explainer_rf.expected_value[1]
    else:  # if shap_values_rf is array with shape (num_samples, num_features, 2)
        # Take class 1
        shap_vals_sample = shap_values_rf[anomaly_idx, :, 1]
        expected_val = explainer_rf.expected_value[1]

    # Create a shap.Explanation object
    shap_exp = shap.Explanation(
        values=shap_vals_sample,
        base_values=expected_val,
        data=X_test_df.iloc[anomaly_idx],
        feature_names=X.columns
    )

    # Draw waterfall plot
    shap.plots.waterfall(shap_exp)

"""**RISK** ***CALCULATION***"""

import pandas as pd
import numpy as np

# Convert X_test back to DataFrame for feature names
X_test_df = pd.DataFrame(X_test, columns=X.columns)
batch_ids = df.iloc[y_test.index]['Batch_ID'].values  # get corresponding Batch IDs

# Predict anomalies using your trained Random Forest
y_pred = rf.predict(X_test)

# Prepare SHAP values for class 1 (anomaly)
if isinstance(shap_values_rf, list):
    shap_vals_class1 = shap_values_rf[1]  # list of shape (num_samples, num_features)
else:
    shap_vals_class1 = shap_values_rf[..., 1]

# --- Calculate raw risk scores ---
risk_scores = []
for i in range(len(X_test_df)):
    shap_vals_sample = shap_vals_class1[i]
    top_indices = np.argsort(np.abs(shap_vals_sample))[::-1][:3]
    risk_score = np.sum(np.abs(shap_vals_sample[top_indices]))
    risk_scores.append(risk_score)

# --- Normalize risk scores (0‚Äì100) ---
min_score = min(risk_scores)
max_score = max(risk_scores)
normalized_scores = [(rs - min_score) / (max_score - min_score) * 100 for rs in risk_scores]

# --- Assign risk levels based on normalized scores ---
risk_levels = []
for score in normalized_scores:
    if score >= 70:
        risk_levels.append("High")
    elif score >= 40:
        risk_levels.append("Medium")
    else:
        risk_levels.append("Low")

# --- Build dashboard table ---
dashboard_table = []
for i in range(len(X_test_df)):
    top_indices = np.argsort(np.abs(shap_vals_class1[i]))[::-1][:3]
    top_features = X.columns[top_indices].tolist()

    dashboard_table.append([
        batch_ids[i],
        y_pred[i],
        top_features[0],
        top_features[1],
        top_features[2],
        risk_levels[i],        # normalized risk level
        round(normalized_scores[i], 2)   # optional numeric score
    ])

# Convert to DataFrame
dashboard_df = pd.DataFrame(dashboard_table, columns=[
    "Batch_ID", "Predicted_Anomaly", "Top_Feature_1",
    "Top_Feature_2", "Top_Feature_3", "Risk_Level", "Risk_Score"
])

# Show first 10 rows
print(dashboard_df.head(10))

# Save the dashboard data for Streamlit
dashboard_df.to_csv("/content/bakery_multivariate_700.csv", index=False)
print("‚úÖ Dashboard CSV saved with Top Features and Risk Level!")

!pip install streamlit pyngrok

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# 
# # Load the processed CSV
# dashboard_df = pd.read_csv("/content/bakery_multivariate_700.csv")
# 
# # Only select required columns for dashboard
# dashboard_df = dashboard_df[[
#     "Batch_ID",
#     "Predicted_Anomaly",
#     "Top_Feature_1",
#     "Top_Feature_2",
#     "Top_Feature_3",
#     "Risk_Level"
# ]]
# 
# # Function to color rows
# def color_row(row):
#     if row['Predicted_Anomaly'] == 1:
#         return ['background-color: #ffcccc']*6  # Red for anomalies
#     else:
#         return ['background-color: #ccffcc']*6  # Green for normal
# 
# # Streamlit page setup
# st.set_page_config(page_title="F&B Dashboard", layout="wide")
# st.title("üçû F&B Manufacturing Anomaly Dashboard")
# 
# # Sidebar filters
# st.sidebar.header("üîç Filters")
# 
# # Filter anomalies
# anomaly_filter = st.sidebar.radio(
#     "Show Batches:",
#     options=["All", "Only Anomalies", "Only Normal"],
#     index=0
# )
# 
# # Filter by risk level
# risk_filter = st.sidebar.multiselect(
#     "Select Risk Levels:",
#     options=dashboard_df["Risk_Level"].unique(),
#     default=list(dashboard_df["Risk_Level"].unique())
# )
# 
# # Apply filters
# filtered_df = dashboard_df.copy()
# 
# if anomaly_filter == "Only Anomalies":
#     filtered_df = filtered_df[filtered_df["Predicted_Anomaly"] == 1]
# elif anomaly_filter == "Only Normal":
#     filtered_df = filtered_df[filtered_df["Predicted_Anomaly"] == 0]
# 
# filtered_df = filtered_df[filtered_df["Risk_Level"].isin(risk_filter)]
# 
# # Show filtered table
# st.dataframe(filtered_df.style.apply(color_row, axis=1))
# 
# st.success(f"Showing {len(filtered_df)} batches after filters.")
# 
# 
#

# Kill existing ngrok processes
!pkill -f ngrok

from pyngrok import ngrok
ngrok.kill()

!pip install pyngrok
from pyngrok import ngrok
# Paste your token here
ngrok.set_auth_token("31g3vFSm8L7VyNPCSwFvUntycCc_7TWRMpydEwwT9tu4abaQA")

from pyngrok import ngrok

# Connect to port 8501 (Streamlit default)
public_url = ngrok.connect(8501)
print(f"‚úÖ Dashboard live at: {public_url}")

"""**Quality Predicition**"""

X_quality = df.drop(['Timestamp','Batch_ID','Quality_Score',
                     'Anomaly_Flag','Maintenance_Required','Energy_Cost_Impact_USD','Root_Cause'], axis=1)

from sklearn.model_selection import train_test_split

X_train_q, X_test_q, y_train_q, y_test_q = train_test_split(
    X_quality, df['Quality_Score'], test_size=0.2, random_state=42
)

# Replace '-' with 0 or mean value
X_train_q.replace('-', 0, inplace=True)
X_test_q.replace('-', 0, inplace=True)

# Or convert to numeric (forces errors to NaN)
X_train_q = X_train_q.apply(pd.to_numeric, errors='coerce')
X_test_q = X_test_q.apply(pd.to_numeric, errors='coerce')

# Fill NaNs with mean
X_train_q.fillna(X_train_q.mean(), inplace=True)
X_test_q.fillna(X_train_q.mean(), inplace=True)

from sklearn.ensemble import RandomForestRegressor
rf_quality = RandomForestRegressor(n_estimators=200, random_state=42)
rf_quality.fit(X_train_q, y_train_q)
y_pred_q = rf_quality.predict(X_test_q)

from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import numpy as np

print("R2:", r2_score(y_test_q, y_pred_q))
rmse = np.sqrt(mean_squared_error(y_test_q, y_pred_q))
print("RMSE:", rmse)
print("MAE:", mean_absolute_error(y_test_q, y_pred_q))

from xgboost import XGBRegressor

xgb_quality = XGBRegressor(
    n_estimators=300,
    learning_rate=0.05,
    max_depth=6,
    random_state=42
)

xgb_quality.fit(X_train_q, y_train_q)
y_pred_xgb = xgb_quality.predict(X_test_q)

print("XGB R2:", r2_score(y_test_q, y_pred_xgb))
print("XGB RMSE:", np.sqrt(mean_squared_error(y_test_q, y_pred_xgb)))
print("XGB MAE:", mean_absolute_error(y_test_q, y_pred_xgb))

alerts = y_pred_q < 80
for i, flag in enumerate(alerts):
    if flag:
        print(f"‚ö† Batch {X_test_q.index[i]} predicted quality low: {y_pred_q[i]}")

import shap
import pandas as pd
import xgboost as xgb

# Ensure X_test_q is a DataFrame
X_test_q_df = pd.DataFrame(X_test_q, columns=X_train_q.columns)
# Assuming you already trained XGB
explainer = shap.TreeExplainer(xgb_quality)
shap_values = explainer.shap_values(X_test_q_df)

# Summary plot (bar) ‚Üí shows top features affecting quality
shap.summary_plot(shap_values, X_test_q_df, plot_type="bar", max_display=10)

# Pick a single batch (e.g., first in test set)
sample_idx = 0

shap.initjs()
shap.force_plot(
    explainer.expected_value,
    shap_values[sample_idx],
    X_test_q_df.iloc[sample_idx],
    feature_names=X_test_q_df.columns
)

# Summary plot for all predictions
shap.summary_plot(shap_values, X_test_q_df)

!pip install dash plotly shap pandas scikit-learn

import joblib
import pandas as pd

# Save XGBoost model
joblib.dump(xgb_quality, 'xgb_quality_model.pkl')

# Save test dataset
X_test_q_df.to_csv('X_test_q_df.csv', index=False)

# Optional: save Anomaly_Flag for dashboard
df.loc[X_test_q_df.index, ['Anomaly_Flag']].to_csv('anomaly_flags.csv', index=False)

# Commented out IPython magic to ensure Python compatibility.
# %%writefile industrial_dashboard_app.py
# import streamlit as st
# import pandas as pd
# import numpy as np
# import plotly.express as px
# import joblib
# import shap
# import os
# 
# # ---------------------- Config ----------------------
# st.set_page_config(page_title="Industrial Monitoring Dashboard", layout="wide")
# st.title("Industrial Monitoring Dashboard üè≠")
# 
# # ---------------------- File Paths ----------------------
# model_file = "xgb_quality_model.pkl"
# test_file = "X_test_q_df.csv"
# anomaly_file = "anomaly_flags.csv"
# 
# # ---------------------- Load Model + Data ----------------------
# if not os.path.exists(model_file):
#     st.error(f"Model file '{model_file}' not found. Upload it or place it in the working directory.")
#     st.stop()
# if not os.path.exists(test_file):
#     st.error(f"Test dataset '{test_file}' not found.")
#     st.stop()
# if not os.path.exists(anomaly_file):
#     st.error(f"Anomaly file '{anomaly_file}' not found.")
#     st.stop()
# 
# xgb_quality = joblib.load(model_file)
# X_test_q_df = pd.read_csv(test_file)
# anomaly_flags = pd.read_csv(anomaly_file)['Anomaly_Flag']
# 
# # ---------------------- Predictions ----------------------
# y_pred_q = xgb_quality.predict(X_test_q_df)
# 
# dashboard_df = X_test_q_df.copy()
# dashboard_df['Predicted_Quality'] = y_pred_q
# dashboard_df['Alert'] = dashboard_df['Predicted_Quality'] < 80
# dashboard_df['Anomaly'] = anomaly_flags.values
# 
# # ---------------------- SHAP Explainer ----------------------
# explainer = shap.TreeExplainer(xgb_quality)
# shap_values = explainer.shap_values(X_test_q_df)
# 
# def get_top_shap_features(idx):
#     shap_vals = shap_values[idx]
#     top_idx = np.argsort(np.abs(shap_vals))[-3:][::-1]
#     features = X_test_q_df.columns[top_idx]
#     values = shap_vals[top_idx]
#     return list(zip(features, values))
# 
# # ---------------------- Sidebar ----------------------
# batch_idx = st.sidebar.selectbox("Select Batch Index", options=dashboard_df.index)
# show_all_batches = st.sidebar.checkbox("Show All Batches Table", value=True)
# show_quality_trend = st.sidebar.checkbox("Show Quality Trend", value=True)
# 
# batch_data = dashboard_df.loc[batch_idx]
# 
# # ---------------------- Batch Alerts ----------------------
# st.subheader(f"Batch {batch_idx} Details")
# st.write(batch_data)
# 
# if batch_data['Alert'] and batch_data['Anomaly']:
#     st.error(f"‚ö† Batch {batch_idx} is ANOMALOUS and LOW QUALITY ({batch_data['Predicted_Quality']:.1f})!")
# elif batch_data['Alert']:
#     st.warning(f"‚ö† Batch {batch_idx} predicted quality LOW ({batch_data['Predicted_Quality']:.1f})!")
# elif batch_data['Anomaly']:
#     st.warning(f"‚ö† Batch {batch_idx} is anomalous but quality is okay.")
# else:
#     st.success(f"‚úÖ Batch {batch_idx} is normal and good quality.")
# 
# # ---------------------- SHAP Top Features ----------------------
# top_features = get_top_shap_features(batch_idx)
# shap_fig = px.bar(
#     x=[f[0] for f in top_features],
#     y=[f[1] for f in top_features],
#     labels={'x':'Feature', 'y':'SHAP Value'},
#     title='Top 3 Features Impacting Quality'
# )
# st.plotly_chart(shap_fig, use_container_width=True)
# 
# # ---------------------- Low Quality Batches ----------------------
# st.subheader("‚ö† Low Quality Batches (Predicted Quality < 80)")
# low_quality_batches = dashboard_df[dashboard_df['Alert']]
# 
# if low_quality_batches.empty:
#     st.success("‚úÖ No low-quality batches detected.")
# else:
#     # Sort by Predicted Quality (lowest first)
#     low_quality_batches = low_quality_batches[['Predicted_Quality', 'Anomaly']].sort_values(by="Predicted_Quality")
# 
#     # Apply color highlighting
#     def highlight_quality(val):
#         color = 'red' if val < 80 else 'green'
#         return f'background-color: {color}; color: white; font-weight: bold;'
# 
#     styled_df = low_quality_batches.style.applymap(highlight_quality, subset=['Predicted_Quality'])
#     st.dataframe(styled_df, use_container_width=True)
# 
# # ---------------------- All Batches Table ----------------------
# if show_all_batches:
#     st.subheader("All Batches Overview")
# 
#     def highlight_rows(row):
#         if row['Alert']:
#             return ['background-color: red; color: white'] * len(row)
#         else:
#             return ['background-color: green; color: white'] * len(row)
# 
#     styled_all = dashboard_df[['Predicted_Quality', 'Alert', 'Anomaly']].style.apply(highlight_rows, axis=1)
#     st.dataframe(styled_all, use_container_width=True)
# 
# # ---------------------- Quality Trend ----------------------
# if show_quality_trend:
#     st.subheader("Quality Trend Across Batches")
#     trend_fig = px.line(
#         dashboard_df,
#         y='Predicted_Quality',
#         title='Predicted Quality Over Batches',
#         labels={'index':'Batch Index', 'Predicted_Quality':'Quality Score'}
#     )
#     trend_fig.add_scatter(
#         x=dashboard_df[dashboard_df['Alert']].index,
#         y=dashboard_df[dashboard_df['Alert']]['Predicted_Quality'],
#         mode='markers',
#         marker=dict(color='red', size=10),
#         name='Low Quality'
#     )
#     st.plotly_chart(trend_fig, use_container_width=True)
#

!pip install pyngrok
from pyngrok import ngrok
# Paste your token here
ngrok.set_auth_token("31g3vFSm8L7VyNPCSwFvUntycCc_7TWRMpydEwwT9tu4abaQA")

# Kill existing ngrok processes
!pkill -f ngrok

# ---------------- Streamlit + ngrok setup ----------------
import os
from pyngrok import ngrok

# 1Ô∏è‚É£ Kill any existing ngrok tunnels
ngrok.kill()

# 2Ô∏è‚É£ Start Streamlit in background on port 8501
os.system("streamlit run industrial_dashboard_app.py --server.port 8501 &")

# 3Ô∏è‚É£ Open ngrok tunnel to the same port
public_url = ngrok.connect(addr="8501", bind_tls=True)
print(f"‚úÖ Dashboard live at: {public_url}")

"""# **Predictive Maintenance**"""

# Prepare the Data

import numpy as np

# Simulate Time-to-Failure (in hours) based on some sensor patterns
np.random.seed(42)
df['Time_to_Failure'] = 50 - 0.1*df['Oven_Temp_C'] - 0.05*df['Mixer_RPM'] + \
                        0.2*np.random.randn(len(df))
df['Time_to_Failure'] = df['Time_to_Failure'].clip(lower=1)  # no negative time

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import xgboost as xgb
import joblib

# Features
X_pm = df[['Oven_Temp_C','Chamber_Humidity_%','Dough_Moisture_%','Mixer_RPM',
           'Mixer_Vibration_mms','Conveyor_Speed_mpm','Energy_kWh']]
y_pm = df['Time_to_Failure']

# Scale features
scaler_pm = StandardScaler()
X_scaled_pm = scaler_pm.fit_transform(X_pm)

# Train-test split
X_train_pm, X_test_pm, y_train_pm, y_test_pm = train_test_split(
    X_scaled_pm, y_pm, test_size=0.2, random_state=42
)

# Train XGBoost Regressor
xgb_pm = xgb.XGBRegressor(
    n_estimators=200,
    learning_rate=0.1,
    max_depth=5,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)

xgb_pm.fit(X_train_pm, y_train_pm)

# Predict
y_pred_pm = xgb_pm.predict(X_test_pm)

# Save model and scaler (so you can use in dashboard later)
joblib.dump(xgb_pm, "xgb_pm_model.pkl")
joblib.dump(scaler_pm, "scaler_pm.pkl")

print("‚úÖ Predictive maintenance model trained with XGBoost")

# SHAP Explanation for Maintenance

import shap
import pandas as pd

# Convert scaled test data back into DataFrame with feature names
X_test_pm_df = pd.DataFrame(X_test_pm, columns=X_pm.columns)

# Use TreeExplainer for XGBoost model
explainer_pm = shap.TreeExplainer(xgb_pm)
shap_values_pm = explainer_pm.shap_values(X_test_pm_df)

# Example: first batch in test
shap.initjs()
shap.force_plot(
    explainer_pm.expected_value,
    shap_values_pm[0],
    X_test_pm_df.iloc[0],
    feature_names=X_pm.columns
)

# Add Alerts
alerts_pm = y_pred_pm < 5  # True if machine needs maintenance soon

import joblib
import pandas as pd

# Save XGBoost models
joblib.dump(xgb_pm, 'xgb_pm_model.pkl')          # Predictive Maintenance model
joblib.dump(xgb_quality, 'xgb_quality_model.pkl') # Quality Prediction model

# Convert X_test_pm (NumPy array) to DataFrame before saving
# Need the original column names from X_pm
X_test_pm_df = pd.DataFrame(X_test_pm, columns=X_pm.columns)
X_test_pm_df.to_csv('X_test_pm.csv', index=False)

# Save the scaler for PM features
joblib.dump(scaler_pm, 'scaler_pm.pkl')

# Save Quality Test Data
X_test_q_df.to_csv('X_test_q_df.csv', index=False)

!pip install gTTS

!pip install gTTS
from gtts import gTTS
import streamlit as st

def alert_voice(message, filename="alert.mp3"):
    tts = gTTS(text=message, lang='en')
    tts.save(filename)
    st.audio(filename, format='audio/mp3')

# Example:
alert_voice("Attention! Batch 3 anomaly detected!")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile industrial_dashboard_app.py
# import streamlit as st
# import pandas as pd
# import numpy as np
# import shap
# import plotly.express as px
# import joblib
# from gtts import gTTS
# import time
# import os
# 
# st.set_page_config(page_title="Industrial Monitoring Dashboard", layout="wide")
# st.title("Industrial Monitoring Dashboard üè≠")
# 
# # ---------------- Helper Function for Voice Alerts ----------------
# def alert_voice_gtts(message):
#     """Generate a unique MP3 filename each time to avoid caching issues."""
#     filename = f"alert_{int(time.time()*1000)}.mp3"
#     tts = gTTS(text=message, lang='en')
#     tts.save(filename)
#     st.audio(filename, format='audio/mp3')
#     # Optional: clean up old files later if many alerts are triggered
#     return filename
# 
# # ---------------- Global CSS for blinking effect ----------------
# st.markdown("""
# <style>
# @keyframes blinker {50% {opacity: 0;}}
# .blink {
#     color: red;
#     font-size: 24px;
#     font-weight: bold;
#     animation: blinker 1s linear infinite;
# }
# </style>
# """, unsafe_allow_html=True)
# 
# # ---------------- Load Models + Data ----------------
# xgb_quality = joblib.load("xgb_quality_model.pkl")
# X_test_q_df = pd.read_csv('X_test_q_df.csv')
# anomaly_flags = pd.read_csv('anomaly_flags.csv')['Anomaly_Flag']
# 
# xgb_pm = joblib.load("xgb_pm_model.pkl")
# X_test_pm = pd.read_csv('X_test_pm.csv')
# y_pm_pred = xgb_pm.predict(X_test_pm)
# pm_alerts = y_pm_pred < 5
# 
# # ---------------- SHAP Explainers ----------------
# explainer_quality = shap.TreeExplainer(xgb_quality)
# shap_values_quality = explainer_quality.shap_values(X_test_q_df)
# 
# explainer_pm = shap.TreeExplainer(xgb_pm)
# shap_values_pm = explainer_pm.shap_values(X_test_pm)
# 
# # ---------------- Prepare Dashboard DataFrame ----------------
# dashboard_df = X_test_q_df.copy()
# dashboard_df['Predicted_Quality'] = xgb_quality.predict(X_test_q_df)
# dashboard_df['Alert_Quality'] = dashboard_df['Predicted_Quality'] < 80
# dashboard_df['Anomaly'] = anomaly_flags.values
# dashboard_df['RUL'] = y_pm_pred
# dashboard_df['Alert_PM'] = pm_alerts
# 
# # ---------------- Single Batch Selection ----------------
# batch_idx = st.selectbox("Select Batch Index", options=dashboard_df.index)
# batch_data = dashboard_df.loc[batch_idx]
# 
# # ---------------- Tabs ----------------
# tab1, tab2, tab3 = st.tabs([
#     "Anomaly Detection",
#     "Quality Prediction",
#     "Predictive Maintenance"
# ])
# 
# # ---------------- Tab 1: Anomaly Detection ----------------
# with tab1:
#     st.header("Anomaly Detection üîç")
# 
#     # Show all anomalies
#     anomaly_batches = dashboard_df[dashboard_df['Anomaly'] == 1]
#     if not anomaly_batches.empty:
#         st.subheader("Batches with Anomalies")
#         st.dataframe(anomaly_batches)
#     else:
#         st.info("No anomalies detected in any batch.")
# 
#     st.write("### Selected Batch")
#     st.write(batch_data)
# 
#     if batch_data['Anomaly']:
#         st.markdown(f"<div class='blink'>‚ö† Batch {batch_idx} ANOMALY DETECTED!</div>", unsafe_allow_html=True)
#         alert_voice_gtts(f"Attention! Batch {batch_idx} anomaly detected!")
#     else:
#         st.success(f"‚úÖ Batch {batch_idx} is normal.")
# 
# with tab2:
#     st.header("Quality Prediction üéØ")
#     st.dataframe(dashboard_df[['Predicted_Quality','Alert_Quality','Anomaly']])
# 
#     # ---------------- Highlight Low-Quality Batches ----------------
#     low_quality_batches = dashboard_df[dashboard_df['Alert_Quality']]
#     if not low_quality_batches.empty:
#         st.warning("‚ö†Ô∏è Low quality predicted for the following batches:")
#         st.dataframe(low_quality_batches)
#         # Voice alert for each low-quality batch
#         for idx in low_quality_batches.index:
#             alert_voice_gtts(f"Batch {idx} predicted quality is low!")
# 
#     # Quality trend
#     trend_fig = px.line(dashboard_df, y='Predicted_Quality', title="Quality Trend Over Batches")
#     trend_fig.add_scatter(
#         x=low_quality_batches.index,
#         y=low_quality_batches['Predicted_Quality'],
#         mode='markers',
#         marker=dict(color='red', size=10),
#         name='Low Quality'
#     )
#     st.plotly_chart(trend_fig, use_container_width=True)
# 
#     # SHAP force plot
#     st.subheader(f"Feature Impact on Quality for Batch {batch_idx}")
#     shap.initjs()
#     force_plot = shap.force_plot(
#         explainer_quality.expected_value,
#         shap_values_quality[batch_idx,:],
#         X_test_q_df.iloc[batch_idx,:],
#         feature_names=X_test_q_df.columns
#     )
#     shap_html = f"<head>{shap.getjs()}</head><body>{force_plot.html()}</body>"
#     st.components.v1.html(shap_html, height=400, scrolling=True)
# 
#     # Blink alert for selected batch if quality is low
#     if dashboard_df.loc[batch_idx, 'Alert_Quality']:
#         st.markdown(f"<div class='blink'>‚ö† Batch {batch_idx} QUALITY ALERT!</div>", unsafe_allow_html=True)
#         alert_voice_gtts(f"Warning! Batch {batch_idx} predicted quality is low!")
# # ---------------- Tab 3: Predictive Maintenance ----------------
# with tab3:
#     st.header("Predictive Maintenance ‚è≥")
# 
#     # ---------------- Create Severity Levels based on quartiles ----------------
#     rul_25 = np.percentile(dashboard_df['RUL'], 25)  # lower quartile
#     rul_50 = np.percentile(dashboard_df['RUL'], 50)  # median
#     rul_75 = np.percentile(dashboard_df['RUL'], 75)  # upper quartile
# 
#     severity = []
#     alerts = []
# 
#     for rul in dashboard_df['RUL']:
#         if rul >= rul_75:
#             severity.append("Safe üü¢")
#             alerts.append(False)
#         elif rul >= rul_50:
#             severity.append("Warning üü°")
#             alerts.append(False)
#         else:
#             severity.append("Critical üî¥")
#             alerts.append(True)
# 
#     dashboard_df['Severity'] = severity
#     dashboard_df['Maintenance_Alert'] = alerts
# 
#     # ---------------- Display full PM table ----------------
#     st.subheader("Remaining Useful Life (RUL) & Severity")
#     st.dataframe(dashboard_df[['RUL','Severity','Maintenance_Alert']])
# 
#     # Highlight Critical Machines
#     critical_machines = dashboard_df[dashboard_df['Maintenance_Alert']]
#     if not critical_machines.empty:
#         st.warning("‚ö†Ô∏è Maintenance REQUIRED for the following batches/machines:")
#         st.dataframe(critical_machines)
#         # Voice alert for each critical machine
#         for idx in critical_machines.index:
#             alert_voice_gtts(f"Batch {idx} requires maintenance soon!")
#     else:
#         st.success("‚úÖ All machines are operating safely.")
# 
#     # ---------------- RUL trend plot ----------------
#     pm_fig = px.line(dashboard_df, y='RUL', title="Remaining Useful Life Over Batches")
#     pm_fig.add_scatter(
#         x=critical_machines.index,
#         y=critical_machines['RUL'],
#         mode='markers',
#         marker=dict(color='red', size=10),
#         name='Critical Maintenance'
#     )
#     st.plotly_chart(pm_fig, use_container_width=True)
# 
#     # ---------------- SHAP force plot for selected batch ----------------
#     batch_idx = st.selectbox("Select Batch Index for SHAP", options=dashboard_df.index)
#     st.subheader(f"Feature Impact on RUL for Batch {batch_idx}")
#     shap.initjs()
#     force_plot_pm = shap.force_plot(
#         explainer_pm.expected_value,
#         shap_values_pm[batch_idx,:],
#         X_test_pm.iloc[batch_idx,:],
#         feature_names=X_test_pm.columns
#     )
#     shap_html_pm = f"<head>{shap.getjs()}</head><body>{force_plot_pm.html()}</body>"
#     st.components.v1.html(shap_html_pm, height=400, scrolling=True)
# 
#     # Blink alert for selected batch if critical
#     if dashboard_df.loc[batch_idx, 'Maintenance_Alert']:
#         st.markdown(f"<div class='blink'>‚ö† Batch {batch_idx} MAINTENANCE REQUIRED!</div>", unsafe_allow_html=True)
#         alert_voice_gtts(f"Maintenance required for machine at batch {batch_idx}!")
# 
# 
# 
# 
#

!pkill -f streamlit

from pyngrok import ngrok
ngrok.kill()

import os
from pyngrok import ngrok

# Run Streamlit app
os.system("streamlit run industrial_dashboard_app.py --server.port 8501 &")

# Open new tunnel
public_url = ngrok.connect(8501, bind_tls=True)
print(f"‚úÖ Dashboard live at: {public_url}")